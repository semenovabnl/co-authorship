{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm \n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBRegressor\n",
    "import collections\n",
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge embbeding functions\n",
    "def avg_sum(v1, v2):\n",
    "    return (np.array(v1)+np.array(v2))/2\n",
    "def mult(v1, v2):\n",
    "    return np.array(v1)*np.array(v2)\n",
    "def w_l1(v1, v2):\n",
    "    return np.abs(np.array(v1)-np.array(v2))\n",
    "def w_l2(v1, v2):\n",
    "    return (np.array(v1)-np.array(v2))**2\n",
    "def nw_l1(v1, v2, graph, n1, n2, embs ):\n",
    "    neig1 = [n for n in graph.neighbors(str(n1))]\n",
    "    neig2 = [n for n in graph.neighbors(str(n2))]\n",
    "    sum1 = np.zeros(len(v1))\n",
    "    sum2 = np.zeros(len(v2))\n",
    "    for n in neig1:\n",
    "        sum1 += np.array(embs[int(n)])\n",
    "    for n in neig2:\n",
    "        sum2 += np.array(embs[int(n)])\n",
    "    return np.abs((sum1+np.array(v1))/(len(neig1)+1)+(sum2+np.array(v2))/(len(neig2)+1))\n",
    "def nw_l2(v1, v2, graph, n1, n2, embs ):\n",
    "    neig1 = [n for n in graph.neighbors(n1)]\n",
    "    neig2 = [n for n in graph.neighbors(n2)]\n",
    "    sum1 = np.zeros(len(v1))\n",
    "    sum2 = np.zeros(len(v2))\n",
    "    for n in neig1:\n",
    "        sum1 += np.array(embs[int(n)])\n",
    "    for n in neig2:\n",
    "        sum2 += np.array(embs[int(n)])\n",
    "    return ((sum1+np.array(v1))/(len(neig1)+1)+(sum2+np.array(v2))/(len(neig2)+1))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load\n",
    "Graph_train = nx.read_weighted_edgelist(\"./edge_list_binary_train_2018.txt\", delimiter=' ',nodetype=int)\n",
    "Graph_test_2018 = nx.read_weighted_edgelist(\"./edge_list_binary.txt\", delimiter=' ',nodetype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_test_2018 = nx.read_weighted_edgelist(\"./edge_list_weighted.txt\", delimiter=' ',nodetype=int)\n",
    "# Graph_test_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_dir = Graph_test_2018.to_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list_dir = list(Graph_dir.edges.data()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_list_dir\n",
    "edge_list_dir_save = [[e[0],e[1],int(list(e[2].values())[0])] for e in edge_list_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = nx.convert_node_labels_to_integers(Graph_test_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46312"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = list(Graph_dir.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = dict(zip(old,int_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = [(key[0],val[0]) for key,val in zipped.items()]\n",
    "second = [(key[1],val[1]) for key,val in zipped.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(first)\n",
    "df_2 = pd.DataFrame(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df_2 = df_2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df, df_2, on=[0,1], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first = df[~df.isin(merged)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39431"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39431"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_edges = list(new.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dir_edge_list_weighted.txt', 'w') as file:\n",
    "    for ind in range(len(edge_list_dir_save)):\n",
    "        file.writelines(str(edge_list_dir_save[ind][0]) + ' ' + str(edge_list_dir_save[ind][1]) + ' '+ str(edge_list_dir_save[ind][2]) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train = open('./edges_train_binary.txt')\n",
    "f_2019 = open('./edges_2019_binary.txt')\n",
    "\n",
    "edges_train = []\n",
    "edges_2019 = []\n",
    "\n",
    "for line in f_train:\n",
    "    edges_train.append(line.split(' '))\n",
    "for line in f_2019:\n",
    "    edges_2019.append(line.split(' '))\n",
    "f_train.close()\n",
    "f_2019.close()\n",
    "\n",
    "for i in range(len(edges_train)):\n",
    "    edges_train[i][2] = edges_train[i][2][:-1]\n",
    "\n",
    "for i in range(len(edges_2019)):\n",
    "    edges_2019[i][2] = edges_2019[i][2][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_2019 = [edge for edge in edges_train if edge not in edges_2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117228"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(edges_train)\n",
    "len(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180473"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_2 = pd.DataFrame(edges_2018)\n",
    "len(dataframe_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('edges_train_binary.txt', sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117228"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge = pd.merge(dataframe, dataframe_2, on=[0,1], how='inner')\n",
    "len(data_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge = data_merge.drop(columns=['2_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge = data_merge.rename(columns={0: 0, 1: 1, '2_x': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019 = dataframe_2[~dataframe_2.isin(data_merge)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019.to_csv('edges_2019_binary.txt',sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63245\n",
      "117228\n"
     ]
    }
   ],
   "source": [
    "print(len(edges_2019))\n",
    "print(len(edges_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edges_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузка ребер с негатив семплинг\n",
    "f_train = open('./edge_list_train_NegSamp.txt')\n",
    "f_2019 = open('./edge_list_2019_NegSamp.txt')\n",
    "\n",
    "edges_train = []\n",
    "edges_2019 = []\n",
    "\n",
    "for line in f_train:\n",
    "    edges_train.append(line.split(' '))\n",
    "for line in f_2019:\n",
    "    edges_2019.append(line.split(' '))\n",
    "f_train.close()\n",
    "f_2019.close()\n",
    "\n",
    "for i in range(len(edges_train)):\n",
    "    edges_train[i][2] = edges_train[i][2][:-1]\n",
    "\n",
    "for i in range(len(edges_2019)):\n",
    "    edges_2019[i][2] = edges_2019[i][2][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_train_dict = {(e[0], e[1]) : e[2] for e in edges_train}\n",
    "edges_2019_dict = {(e[0], e[1]) : e[2] for e in edges_2019}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "CPU times: user 9min 57s, sys: 1.21 s, total: 9min 58s\n",
      "Wall time: 3min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculating embeddings (finding best parameters: 'p' and 'q')\n",
    "# Source: https://github.com/aditya-grover/node2vec\n",
    "# values = [0.25,0.5,1,2,4] # d=64\n",
    "# for x in values:\n",
    "#     for y in values:\n",
    "%run /home/natalia-s/Documents/makarov_jcdl/jcdl2018/Core_Code_for_XLSX_results/node2vec-master/src/main.py --input ./edge_list_weighted.txt --output ./Data/emb_done/out.txt --walk-length 60 --num-walks 10 --q 2 --p 0.5 --weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "CPU times: user 6min 29s, sys: 849 ms, total: 6min 30s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculating embeddings (finding best parameters: 'p' and 'q')\n",
    "# Source: https://github.com/aditya-grover/node2vec\n",
    "# values = [0.25,0.5,1,2,4] # d=64\n",
    "# for x in values:\n",
    "#     for y in values:\n",
    "%run /home/natalia-s/Documents/makarov_jcdl/jcdl2018/Core_Code_for_XLSX_results/node2vec-master/src/main.py --input ./edge_list_weighted_train_2018.txt --output ./Data/emb_done/out_2018.txt --walk-length 60 --num-walks 10 --q 2 --p 0.5 --weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_train = []\n",
    "for e in edges_train:\n",
    "    nodes_train.extend(e[:2]) # экстендим парами и убираем дубликаты вершин\n",
    "nodes_train = set(nodes_train)\n",
    "\n",
    "nodes_2019 = []\n",
    "for e in edges_2019:\n",
    "    nodes_2019.extend(e[:2])\n",
    "nodes_2019 = set(nodes_2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative sampling\n",
    "k = 0\n",
    "neg_sample_train = []\n",
    "while k != len(edges_train):\n",
    "    i = np.random.choice(list(nodes_train))\n",
    "    j = np.random.choice(list(nodes_train))\n",
    "    if i!=j and (i,j) not in edges_train_dict.keys():\n",
    "        neg_sample_train.append((i,j))\n",
    "        k +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('neg_sample_train.txt', 'w') as file:\n",
    "    for ind in range(len(neg_sample_train)):\n",
    "        file.writelines(neg_sample_train[ind][0] + ' ' + neg_sample_train[ind][1] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e_e in neg_sample_train:\n",
    "    edges_train_dict[e_e] = 0\n",
    "    edges_train.append([e_e[0],e_e[1], '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edge_list_train_NegSamp.txt', 'w') as file:\n",
    "    for ind in range(len(edges_train)):\n",
    "        file.writelines(edges_train[ind][0] + ' ' + edges_train[ind][1] + ' ' + edges_train[ind][2] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "neg_sample_2019 = []\n",
    "while k != len(edges_2019):\n",
    "    i = np.random.choice(list(nodes_2019))\n",
    "    j = np.random.choice(list(nodes_2019))\n",
    "    if i!=j and (i,j) not in edges_2019_dict.keys():\n",
    "        neg_sample_2019.append((i,j))\n",
    "        k +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('neg_sample_2019.txt', 'w') as file:\n",
    "    for ind in range(len(neg_sample_2019)):\n",
    "        file.writelines(neg_sample_2019[ind][0] + ' ' + neg_sample_2019[ind][1] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e_e in neg_sample_2019:\n",
    "    edges_2019_dict[e_e] = 0\n",
    "    edges_2019.append([e_e[0],e_e[1], '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edge_list_2019_NegSamp.txt', 'w') as file:\n",
    "    for ind in range(len(edges_2019)):\n",
    "        file.writelines(edges_2019[ind][0] + ' ' + edges_2019[ind][1] + ' ' + edges_2019[ind][2] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "# f_emb_train = open('./Data/emb_done/out_2018.txt')\n",
    "f_emb = open('./Data/emb_done/out.txt')\n",
    "emb = []\n",
    "# emb_2018 = []\n",
    "for line in f_emb:\n",
    "    emb.append(line.split(' '))\n",
    "# for line in f_emb_2018:\n",
    "#     emb_2018.append(line.split(' '))\n",
    "f_emb.close()\n",
    "# f_emb_2018.close()\n",
    "\n",
    "\n",
    "for i in range(len(emb)):\n",
    "    emb[i][len(emb[i])-1] = emb[i][len(emb[i])-1][:-1] # для удаления /n на конце последнего числа эмбеддинга\n",
    "# for i in range(len(emb_2018)):\n",
    "#     emb_2018[i][len(emb_2018[i])-1] = emb_2018[i][len(emb_2018[i])-1][:-1]\n",
    "    \n",
    "emb_dict = {} \n",
    "for i in range(1,len(emb)):\n",
    "    emb_dict[int(emb[i][0])] = [float(j) for j in emb[i][1:]] # собираем эмбеддинг в ключ-значение\n",
    "# emb_2018_dict = {} \n",
    "# for i in range(1,len(emb_2018)):\n",
    "#     emb_2018_dict[int(emb_2018[i][0])] = [float(j) for j in emb_2018[i][1:]]\n",
    "\n",
    "for e in edges_2019:\n",
    "    if (e[0] in nodes_2019) and (e[1] in nodes_2019):\n",
    "        emb1 = emb_dict[int(e[0])]\n",
    "        emb2 = emb_dict[int(e[1])]\n",
    "        w_19 = int(e[2])\n",
    "        y_test.append(w_19)\n",
    "#         res = nw_l2(emb1, emb2, Graph_test_2018,int(e[0]),int(e[1]),emb_2018_dict)\n",
    "        res = mult(emb1, emb2)\n",
    "#         try:\n",
    "#             w_train = float(edges_2018_dict[(e[0], e[1])])\n",
    "#         except  KeyError :\n",
    "#             w_train = 0\n",
    "        #res = np.append(res,w_16)\n",
    "        X_test.append(res)\n",
    "\n",
    "for e in edges_train:\n",
    "    if (e[0] in nodes_train) and (e[1] in nodes_train):\n",
    "        emb1 = emb_dict[int(e[0])]\n",
    "        emb2 = emb_dict[int(e[1])]\n",
    "        w_train = int(e[2])\n",
    "        y_train.append(w_train)\n",
    "#         res = nw_l2(emb1, emb2, Graph_train,int(e[0]),int(e[1]),emb_train_dict)\n",
    "        res = mult(emb1, emb2)\n",
    "#         try:\n",
    "#             w_15 = float(edges_2015_dict[(e[0], e[1])])\n",
    "#         except  KeyError :\n",
    "#             w_15 = 0\n",
    "        #res = np.append(res,w_15)\n",
    "        X_train.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126490"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_svm(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # SVC\n",
    "#     y_train = label_binarize(y_train, classes=[0, 1, 2, 3, 4])\n",
    "    svm_model = svm.SVC()\n",
    "#     svm_model = svm.SVC(probability=True)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "#     print(X_train, \"X_train\")\n",
    "#     print(y_train, 'y_train')\n",
    "                     \n",
    "    y_pred_train = svm_model.predict(X_train)\n",
    "    y_pred_test = svm_model.predict(X_test)\n",
    "#     y_pred_train_proba = svm_model.predict_proba(X_train)\n",
    "#     y_pred_test_proba = svm_model.predict_proba(X_test)\n",
    "#     print(y_pred_train_proba[0])\n",
    "\n",
    "#     print(y_pred_train, 'y_pred_train')\n",
    "#     labels = [0,1]\n",
    "    \n",
    "    precision_train = precision_score(y_train, y_pred_train, average=None)\n",
    "    precision_test = precision_score(y_test, y_pred_test, average=None)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "    f1_macro_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "    f1_micro_train = f1_score(y_train, y_pred_train, average='micro')\n",
    "    f1_micro_test = f1_score(y_test, y_pred_test, average='micro')\n",
    "    logloss_train = log_loss(y_train, y_pred_train)\n",
    "    logloss_test = log_loss(y_test, y_pred_test)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    return precision_train, precision_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, logloss_train, logloss_test, roc_auc_train, roc_auc_test, y_pred_train, y_pred_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rf(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # RandomForest\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_pred_train = rf.predict(X_train)\n",
    "    y_pred_test = rf.predict(X_test)\n",
    "    \n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "    f1_macro_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "    f1_micro_train = f1_score(y_train, y_pred_train, average='micro')\n",
    "    f1_micro_test = f1_score(y_test, y_pred_test, average='micro')\n",
    "    logloss_train = log_loss(y_train, y_pred_train)\n",
    "    logloss_test = log_loss(y_test, y_pred_test)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    return precision_train, precision_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, logloss_train, logloss_test, roc_auc_train, roc_auc_test, y_pred_train, y_pred_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_gbc(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # GradientBoosting\n",
    "    params = {'n_estimators': 100, 'max_depth': 4, 'min_samples_split': 2,\n",
    "              'learning_rate': 0.01}\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "                     \n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "    f1_macro_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "    f1_micro_train = f1_score(y_train, y_pred_train, average='micro')\n",
    "    f1_micro_test = f1_score(y_test, y_pred_test, average='micro')\n",
    "    logloss_train = log_loss(y_train, y_pred_train)\n",
    "    logloss_test = log_loss(y_test, y_pred_test)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    return precision_train, precision_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, logloss_train, logloss_test, roc_auc_train, roc_auc_test, y_pred_train, y_pred_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_xgb(X_train, y_train, X_test, y_test):\n",
    "#     param = {\n",
    "#    'max_depth': 3,\n",
    "#    'eta': 0.3, \n",
    "#    'silent': 1, \n",
    "#    'objective': 'multi:softprob',\n",
    "#    'num_class': 2}\n",
    "#     num_round = 20\n",
    "    param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "    num_round = 10\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "#     clf = xgboost.XGBClassifier()\n",
    "    clf = xgb.train(param, dtrain, num_round)\n",
    "#     clf = XGBRegressor()\n",
    "#     clf.fit(X_train, y_train, verbose=False)\n",
    "    evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    clf = xgb.train(param, dtrain, num_round)\n",
    "    \n",
    "#     clf.fit(X_train, y_train)\n",
    "#     predictions = [round(value) for value in y_pred]\n",
    "    y_pred_train_prob = clf.predict(dtrain)\n",
    "    y_pred_train = [int(round(value)) for value in y_pred_train_prob]\n",
    "    y_pred_test_prob = clf.predict(dtest)\n",
    "    y_pred_test = [int(round(value)) for value in y_pred_test_prob]\n",
    "#     print(y_pred_test)\n",
    "    \n",
    "#     y_pred_train = clf.predict(X_train)\n",
    "#     y_pred_train = np.asarray([np.argmax(line) for line in y_pred_train])\n",
    "#     print(y_pred_train[0])\n",
    "#     y_pred_test = clf.predict(X_test)\n",
    "#     y_pred_test = np.asarray([np.argmax(line) for line in y_pred_test])\n",
    "\n",
    "    \n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "    f1_macro_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "    f1_micro_train = f1_score(y_train, y_pred_train, average='micro')\n",
    "    f1_micro_test = f1_score(y_test, y_pred_test, average='micro')\n",
    "    logloss_train = log_loss(y_train, y_pred_train_prob)\n",
    "    logloss_test = log_loss(y_test, y_pred_test_prob)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    return precision_train, precision_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, logloss_train, logloss_test, roc_auc_train, roc_auc_test, y_pred_train, y_pred_test  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "precision_train, precision_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, logloss_train, logloss_test, roc_auc_train, roc_auc_test, y_pred_train, y_pred_test  = model_svm(X_train, y_train, X_test, y_test)\n",
    "print('Precision train: ' + str(precision_train))\n",
    "print('Accuracy train: ' + str(accuracy_train))\n",
    "print('F-1 (macro) train: ' + str(f1_macro_train))\n",
    "print('F-1 (micro) train: ' + str(f1_micro_train))\n",
    "print('Logloss train: ' + str(logloss_train))\n",
    "print('ROC-AUC train: ' + str(roc_auc_train))\n",
    "print('-------------------------------------------------')\n",
    "print('Precision test: ' + str(precision_test))\n",
    "print('Accuracy test: ' + str(accuracy_test))\n",
    "print('F-1 (macro) train: ' + str(f1_macro_test))\n",
    "print('F-1 (micro) train: ' + str(f1_micro_test))\n",
    "print('Logloss train: ' + str(logloss_test))\n",
    "print('ROC-AUC train: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision train: 0.9997778499290828\n",
      "Accuracy train: 0.9989678233869042\n",
      "F-1 (macro) train: 0.998967822709046\n",
      "F-1 (micro) train: 0.9989678233869042\n",
      "Logloss train: 0.03565020591113815\n",
      "ROC-AUC train: 0.9989678233869042\n",
      "-------------------------------------------------\n",
      "Precision train: 0.8361221779548472\n",
      "Accuracy train: 0.5771334216198545\n",
      "F-1 (macro) train: 0.5034299363620667\n",
      "F-1 (micro) train: 0.5771334216198545\n",
      "Logloss train: 14.605309230676509\n",
      "ROC-AUC train: 0.5771334216198545\n",
      "CPU times: user 47.4 s, sys: 96.5 ms, total: 47.5 s\n",
      "Wall time: 47.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#model_rf\n",
    "#nw_l2\n",
    "precision_train, precision_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, logloss_train, logloss_test, roc_auc_train, roc_auc_test, y_pred_train, y_pred_test  = model_rf(X_train, y_train, X_test, y_test)\n",
    "print('Precision train: ' + str(precision_train))\n",
    "print('Accuracy train: ' + str(accuracy_train))\n",
    "print('F-1 (macro) train: ' + str(f1_macro_train))\n",
    "print('F-1 (micro) train: ' + str(f1_micro_train))\n",
    "print('Logloss train: ' + str(logloss_train))\n",
    "print('ROC-AUC train: ' + str(roc_auc_train))\n",
    "print('-------------------------------------------------')\n",
    "print('Precision test: ' + str(precision_test))\n",
    "print('Accuracy test: ' + str(accuracy_test))\n",
    "print('F-1 (macro) train: ' + str(f1_macro_test))\n",
    "print('F-1 (micro) train: ' + str(f1_micro_test))\n",
    "print('Logloss train: ' + str(logloss_test))\n",
    "print('ROC-AUC train: ' + str(roc_auc_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision train: 0.9996844188188735\n",
      "Accuracy train: 0.9997526188282663\n",
      "F-1 (macro) train: 0.9997526188271142\n",
      "F-1 (micro) train: 0.9997526188282663\n",
      "Logloss train: 0.008544369160993838\n",
      "ROC-AUC train: 0.9997526188282663\n",
      "-------------------------------------------------\n",
      "Precision test: 0.9968255973720368\n",
      "Accuracy test: 0.9974069096371254\n",
      "F-1 (macro) train: 0.9974069087496245\n",
      "F-1 (micro) train: 0.9974069096371254\n",
      "Logloss train: 0.08956343882215431\n",
      "ROC-AUC train: 0.9974069096371255\n",
      "CPU times: user 1min 5s, sys: 79.8 ms, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#2019 mult\n",
    "precision_train, precision_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, logloss_train, logloss_test, roc_auc_train, roc_auc_test, y_pred_train, y_pred_test  = model_rf(X_train, y_train, X_test, y_test)\n",
    "print('Precision train: ' + str(precision_train))\n",
    "print('Accuracy train: ' + str(accuracy_train))\n",
    "print('F-1 (macro) train: ' + str(f1_macro_train))\n",
    "print('F-1 (micro) train: ' + str(f1_micro_train))\n",
    "print('Logloss train: ' + str(logloss_train))\n",
    "print('ROC-AUC train: ' + str(roc_auc_train))\n",
    "print('-------------------------------------------------')\n",
    "print('Precision test: ' + str(precision_test))\n",
    "print('Accuracy test: ' + str(accuracy_test))\n",
    "print('F-1 (macro) train: ' + str(f1_macro_test))\n",
    "print('F-1 (micro) train: ' + str(f1_micro_test))\n",
    "print('Logloss train: ' + str(logloss_test))\n",
    "print('ROC-AUC train: ' + str(roc_auc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision train: 0.9997696835281071\n",
      "Accuracy train: 0.9997782099839628\n",
      "F-1 (macro) train: 0.9997782099839467\n",
      "F-1 (micro) train: 0.9997782099839628\n",
      "Logloss train: 0.007660447852331377\n",
      "ROC-AUC train: 0.9997782099839628\n",
      "-------------------------------------------------\n",
      "Precision test: 0.9851842842848376\n",
      "Accuracy test: 0.9863026602317244\n",
      "F-1 (macro) train: 0.9863026420372716\n",
      "F-1 (micro) train: 0.9863026602317244\n",
      "Logloss train: 0.4730952924192307\n",
      "ROC-AUC train: 0.9863026602317244\n",
      "CPU times: user 1min 6s, sys: 128 ms, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#model_rf\n",
    "#mult embed\n",
    "precision_train, precision_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, logloss_train, logloss_test, roc_auc_train, roc_auc_test, y_pred_train, y_pred_test  = model_rf(X_train, y_train, X_test, y_test)\n",
    "print('Precision train: ' + str(precision_train))\n",
    "print('Accuracy train: ' + str(accuracy_train))\n",
    "print('F-1 (macro) train: ' + str(f1_macro_train))\n",
    "print('F-1 (micro) train: ' + str(f1_micro_train))\n",
    "print('Logloss train: ' + str(logloss_train))\n",
    "print('ROC-AUC train: ' + str(roc_auc_train))\n",
    "print('-------------------------------------------------')\n",
    "print('Precision test: ' + str(precision_test))\n",
    "print('Accuracy test: ' + str(accuracy_test))\n",
    "print('F-1 (macro) train: ' + str(f1_macro_test))\n",
    "print('F-1 (micro) train: ' + str(f1_micro_test))\n",
    "print('Logloss train: ' + str(logloss_test))\n",
    "print('ROC-AUC train: ' + str(roc_auc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8814461273156414\n",
      "Accuracy: 0.8736010168219197\n",
      "F-1 (macro): 0.8735876489822981\n",
      "F-1 (micro): 0.8736010168219197\n",
      "Logloss: 0.35416527515648294\n",
      "ROC-AUC: 0.8736010168219195\n",
      "-------------------------------------------------\n",
      "Precision train: 0.5696553377602767\n",
      "Accuracy train: 0.6062485801200179\n",
      "F-1 (macro) train: 0.5770673062661725\n",
      "F-1 (micro) train: 0.6062485801200179\n",
      "Logloss train: nan\n",
      "ROC-AUC train: 0.606248580120018\n",
      "CPU times: user 32.9 s, sys: 1.98 s, total: 34.9 s\n",
      "Wall time: 34.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#model_xgb\n",
    "#nw_l2\n",
    "precision_train, precision_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, logloss_train, logloss_test, roc_auc_train, roc_auc_test, y_pred_train, y_pred_test  = model_xgb(X_train, y_train, X_test, y_test)\n",
    "print('Precision: ' + str(precision_train))\n",
    "print('Accuracy: ' + str(accuracy_train))\n",
    "print('F-1 (macro): ' + str(f1_macro_train))\n",
    "print('F-1 (micro): ' + str(f1_micro_train))\n",
    "print('Logloss: ' + str(logloss_train))\n",
    "print('ROC-AUC: ' + str(roc_auc_train))\n",
    "print('-------------------------------------------------')\n",
    "print('Precision train: ' + str(precision_test))\n",
    "print('Accuracy train: ' + str(accuracy_test))\n",
    "print('F-1 (macro) train: ' + str(f1_macro_test))\n",
    "print('F-1 (micro) train: ' + str(f1_micro_test))\n",
    "print('Logloss train: ' + str(logloss_test))\n",
    "print('ROC-AUC train: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9874320968821769\n",
      "Accuracy: 0.9906379022076637\n",
      "F-1 (macro): 0.9906378009649159\n",
      "F-1 (micro): 0.9906379022076637\n",
      "Logloss: 0.029438242443460647\n",
      "ROC-AUC: 0.9906379022076637\n",
      "-------------------------------------------------\n",
      "Precision train: 0.9883468919810283\n",
      "Accuracy train: 0.9916594197169737\n",
      "F-1 (macro) train: 0.9916593237761457\n",
      "F-1 (micro) train: 0.9916594197169737\n",
      "Logloss train: 0.02766281220040771\n",
      "ROC-AUC train: 0.9916594197169736\n",
      "CPU times: user 51.8 s, sys: 1.36 s, total: 53.2 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#model_xgb\n",
    "#2019 mult\n",
    "precision_train, precision_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, logloss_train, logloss_test, roc_auc_train, roc_auc_test, y_pred_train, y_pred_test  = model_xgb(X_train, y_train, X_test, y_test)\n",
    "print('Precision: ' + str(precision_train))\n",
    "print('Accuracy: ' + str(accuracy_train))\n",
    "print('F-1 (macro): ' + str(f1_macro_train))\n",
    "print('F-1 (micro): ' + str(f1_micro_train))\n",
    "print('Logloss: ' + str(logloss_train))\n",
    "print('ROC-AUC: ' + str(roc_auc_train))\n",
    "print('-------------------------------------------------')\n",
    "print('Precision train: ' + str(precision_test))\n",
    "print('Accuracy train: ' + str(accuracy_test))\n",
    "print('F-1 (macro) train: ' + str(f1_macro_test))\n",
    "print('F-1 (micro) train: ' + str(f1_micro_test))\n",
    "print('Logloss train: ' + str(logloss_test))\n",
    "print('ROC-AUC train: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9869626766353873\n",
      "Accuracy: 0.9900407752414099\n",
      "F-1 (macro): 0.9900406757596212\n",
      "F-1 (micro): 0.9900407752414099\n",
      "Logloss: 0.03003821213053024\n",
      "ROC-AUC: 0.99004077524141\n",
      "-------------------------------------------------\n",
      "Precision train: 0.9256401371556241\n",
      "Accuracy train: 0.9560266632681897\n",
      "F-1 (macro) train: 0.9559705636259489\n",
      "F-1 (micro) train: 0.9560266632681897\n",
      "Logloss train: 0.1347615421745948\n",
      "ROC-AUC train: 0.9560266632681899\n",
      "CPU times: user 58.6 s, sys: 2.17 s, total: 1min\n",
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#mult\n",
    "precision_train, precision_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, logloss_train, logloss_test, roc_auc_train, roc_auc_test, y_pred_train, y_pred_test  = model_xgb(X_train, y_train, X_test, y_test)\n",
    "print('Precision: ' + str(precision_train))\n",
    "print('Accuracy: ' + str(accuracy_train))\n",
    "print('F-1 (macro): ' + str(f1_macro_train))\n",
    "print('F-1 (micro): ' + str(f1_micro_train))\n",
    "print('Logloss: ' + str(logloss_train))\n",
    "print('ROC-AUC: ' + str(roc_auc_train))\n",
    "print('-------------------------------------------------')\n",
    "print('Precision train: ' + str(precision_test))\n",
    "print('Accuracy train: ' + str(accuracy_test))\n",
    "print('F-1 (macro) train: ' + str(f1_macro_test))\n",
    "print('F-1 (micro) train: ' + str(f1_micro_test))\n",
    "print('Logloss train: ' + str(logloss_test))\n",
    "print('ROC-AUC train: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 3.81 µs\n",
      "Precision: 0.9867962744815546\n",
      "Accuracy: 0.9899895929300168\n",
      "F-1 (macro): 0.9899894852372865\n",
      "F-1 (micro): 0.9899895929300168\n",
      "Logloss: 0.34575252487311825\n",
      "ROC-AUC: 0.9899895929300168\n",
      "-------------------------------------------------\n",
      "Precision train: 0.9910365469439193\n",
      "Accuracy train: 0.9928610957387936\n",
      "F-1 (macro) train: 0.9928610710979033\n",
      "F-1 (micro) train: 0.9928610957387936\n",
      "Logloss train: 0.24657261487502763\n",
      "ROC-AUC train: 0.9928610957387936\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "#model_gbc\n",
    "precision_train, precision_test, accuracy_train, accuracy_test, f1_macro_train, f1_macro_test, f1_micro_train, f1_micro_test, logloss_train, logloss_test, roc_auc_train, roc_auc_test, y_pred_train, y_pred_test  = model_gbc(X_train, y_train, X_test, y_test)\n",
    "print('Precision: ' + str(precision_train))\n",
    "print('Accuracy: ' + str(accuracy_train))\n",
    "print('F-1 (macro): ' + str(f1_macro_train))\n",
    "print('F-1 (micro): ' + str(f1_micro_train))\n",
    "print('Logloss: ' + str(logloss_train))\n",
    "print('ROC-AUC: ' + str(roc_auc_train))\n",
    "print('-------------------------------------------------')\n",
    "print('Precision train: ' + str(precision_test))\n",
    "print('Accuracy train: ' + str(accuracy_test))\n",
    "print('F-1 (macro) train: ' + str(f1_macro_test))\n",
    "print('F-1 (micro) train: ' + str(f1_micro_test))\n",
    "print('Logloss train: ' + str(logloss_test))\n",
    "print('ROC-AUC train: ' + str(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234456\n",
      "234456\n",
      "360946\n",
      "360946\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lasso(X_train, y_train, X_test, y_test):\n",
    "    MSE_train= []\n",
    "    CV_train = []\n",
    "    MSE_test= []\n",
    "    CV_test = []\n",
    "    MAE_train = []\n",
    "    MAPE_train =[]\n",
    "    MAE_test = []\n",
    "    MAPE_test =[]\n",
    "    \n",
    "    #  Lasso\n",
    "    lasso = Lasso(alpha = 0.016)\n",
    "    y_pred_lasso_train = lasso.fit(X_train, y_train).predict(X_train)\n",
    "    y_pred_lasso = lasso.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    MSE_train.append(np.mean((y_pred_lasso_train - y_train) ** 2))\n",
    "    MSE_test.append(np.mean((y_pred_lasso - y_test) ** 2))\n",
    "     \n",
    "    scores1 = cross_val_score(lasso, X_train, y_train, cv=10,scoring='neg_mean_squared_error')\n",
    "    CV_train.append([scores1.mean(), scores1.std() * 2])\n",
    "    scores2 = cross_val_score(lasso, X_test, y_test, cv=10,scoring='neg_mean_squared_error')\n",
    "    CV_test.append([scores2.mean(), scores2.std() * 2])\n",
    "    \n",
    "    MAE_train.append(metrics.mean_absolute_error(y_train, y_pred_lasso_train))\n",
    "    MAE_test.append(metrics.mean_absolute_error(y_test, y_pred_lasso))\n",
    "    \n",
    "    MAPE_train.append(np.mean(np.abs((y_train - y_pred_lasso_train) / y_train)) * 100)\n",
    "    MAPE_test.append(np.mean(np.abs((y_test - y_pred_lasso) / y_test)) * 100)\n",
    "\n",
    "    return MSE_train[0], CV_train[0], MSE_test[0], CV_test[0], MAE_train[0], MAPE_train[0], MAE_test[0], MAPE_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natalia-s/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/natalia-s/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "MSE_train= []\n",
    "CV_train = []\n",
    "MSE_test= []\n",
    "CV_test = []\n",
    "MAE_train = []\n",
    "MAPE_train =[]\n",
    "MAE_test = []\n",
    "MAPE_test =[]\n",
    "\n",
    "# X_train = []\n",
    "# y_train = []\n",
    "# X_test = []\n",
    "# y_test = []\n",
    "# f_emb_2015 = open('/Users/olgagerasimova/Desktop/Data/emb_new_nw/out15nw_'+str(x)+'_'+str(y)+'.txt')\n",
    "# f_emb_2016 = open('/Users/olgagerasimova/Desktop/Data/emb_new_nw/out16nw_'+str(x)+'_'+str(y)+'.txt')\n",
    "# emb_2015 = []\n",
    "# emb_2016 = []\n",
    "# for line in f_emb_2015:\n",
    "#     emb_2015.append(line.split(' '))\n",
    "# for line in f_emb_2016:\n",
    "#     emb_2016.append(line.split(' '))\n",
    "# f_emb_2015.close()\n",
    "# f_emb_2016.close()\n",
    "# for i in range(len(emb_2016)):\n",
    "#     emb_2016[i][len(emb_2016[i])-1] = emb_2016[i][len(emb_2016[i])-1][:-1]\n",
    "# for i in range(len(emb_2015)):\n",
    "#     emb_2015[i][len(emb_2015[i])-1] = emb_2015[i][len(emb_2015[i])-1][:-1]\n",
    "# emb_2015_dict = {} \n",
    "# for i in range(1,len(emb_2015)):\n",
    "#     emb_2015_dict[int(emb_2015[i][0])] = [float(j) for j in emb_2015[i][1:]]\n",
    "# emb_2016_dict = {} \n",
    "# for i in range(1,len(emb_2016)):\n",
    "#     emb_2016_dict[int(emb_2016[i][0])] = [float(j) for j in emb_2016[i][1:]]\n",
    "\n",
    "# for e in edges_2017:\n",
    "#     if (e[0] in nodes_2016) and (e[1] in nodes_2016):\n",
    "#         emb1 = emb_2016_dict[int(e[0])]\n",
    "#         emb2 = emb_2016_dict[int(e[1])]\n",
    "#         w_17 = float(e[2])\n",
    "#         y_test.append(w_17)\n",
    "#         res = avg_sum(emb1, emb2)\n",
    "#         try:\n",
    "#             w_16 = float(edges_2016_dict[(e[0], e[1])])\n",
    "#         except  KeyError :\n",
    "#             w_16 = 0\n",
    "#         #res = np.append(res,w_16)\n",
    "#         X_test.append(res)\n",
    "\n",
    "# for e in edges_2016:\n",
    "#     if (e[0] in nodes_2015) and (e[1] in nodes_2015):\n",
    "#         emb1 = emb_2015_dict[int(e[0])]\n",
    "#         emb2 = emb_2015_dict[int(e[1])]\n",
    "#         w_16 = float(e[2])\n",
    "#         y_train.append(w_16)\n",
    "#         res = avg_sum(emb1, emb2)\n",
    "#         try:\n",
    "#             w_15 = float(edges_2015_dict[(e[0], e[1])])\n",
    "#         except  KeyError :\n",
    "#             w_15 = 0\n",
    "#         #res = np.append(res,w_15)\n",
    "#         X_train.append(res)\n",
    "\n",
    "mse_train, cv_train, mse_test,cv_test, mae_train, mape_train, mae_test,mape_test = model_lasso(X_train, y_train, X_test, y_test)\n",
    "MSE_train.append(mse_train)\n",
    "CV_train.append( cv_train)\n",
    "MSE_test.append(mse_test)\n",
    "CV_test.append(cv_test)\n",
    "MAE_train.append(mae_train)\n",
    "MAPE_train.append(mape_train)\n",
    "MAE_test.append(mae_test)\n",
    "MAPE_test.append(mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "f_res = open('res_pq_lasso_negsamp.txt','w')\n",
    "for i in range(len(MSE_train)):\n",
    "    f_res.write(str(MSE_train[i])+\"  \"+str(CV_train[i][0]) +\"  \"+ str(CV_train[i][1])+\"  \"+str(MSE_test[i])+\"  \"\\\n",
    "                +str(CV_test[i][0]) +\"  \"+ str(CV_test[i][1])+\"  \"+str(MAE_train[i])+\"  \"+str(MAPE_train[i]) +\"  \"\\\n",
    "                + str(MAE_test[i])+ \"  \"+str(MAPE_test[i])+'\\n')\n",
    "f_res.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0906746807176951]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11878197790002845]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[inf]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
